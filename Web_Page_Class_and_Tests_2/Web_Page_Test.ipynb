{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Web_Page_Class_and_Tests_2.Web_Page_Class import WebPage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example = WebPage(url = \"https://www.apple.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.view_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.path_exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.truncated_url + \".html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.download_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.download_page_to_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.view_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_2 = WebPage(url = \"https://www.apple.com\") \n",
    "\n",
    "web_page_example_2.download_page_to_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_2.view_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_3 = WebPage(url = \"https://github.com\") \n",
    "\n",
    "web_page_example_3.download_page_to_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_3.view_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example.llm_edit_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_4 = WebPage(url = \"https://www.selenium.dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_4.download_page_to_folder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_4.view_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page_example_4.llm_edit_page()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def split_html(html_content, max_chunk_size=5000):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    chunks = []\n",
    "    current_chunk = ''\n",
    "    current_size = 0\n",
    "\n",
    "    # Iterate over direct children of the body\n",
    "    for element in soup.body.contents:\n",
    "        html_string = str(element)\n",
    "        element_size = len(html_string)\n",
    "\n",
    "        if current_size + element_size > max_chunk_size and current_chunk:\n",
    "            chunks.append(current_chunk)\n",
    "            current_chunk = ''\n",
    "            current_size = 0\n",
    "\n",
    "        current_chunk += html_string\n",
    "        current_size += element_size\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk)\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the HTML file\n",
    "with open('html_links/www.selenium.dev.html', 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Split the HTML into chunks\n",
    "chunks = split_html(html_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from Web_Page_Class_and_Tests_2.Web_Page_Prompt_Templates.Chunks import template_chunks\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def llm_edit_chunk(html_chunk: str):\n",
    "    prompt_template = ChatPromptTemplate.from_template(template = template_chunks) \n",
    "    chain = prompt_template | ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0) \n",
    "    output = chain.invoke(input = {\"original_html_code_chunk\": html_chunk}) \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output = llm_edit_chunk(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "with open(\"example_output_file.html\", \"w\") as file: \n",
    "    file.write(example_output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(url = \"example_output_file.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each chunk with the LLM\n",
    "import concurrent.futures\n",
    "\n",
    "# Process each chunk with the LLM concurrently\n",
    "processed_chunks = []\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(llm_edit_chunk, chunk) for chunk in chunks]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        processed_chunks.append(future.result().content)\n",
    "\n",
    "# Combine the processed chunks\n",
    "processed_html_body = ''.join(processed_chunks)\n",
    "\n",
    "# Reconstruct the HTML with the original head and new body\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "soup.body.clear()\n",
    "soup.body.append(BeautifulSoup(processed_html_body, 'html.parser'))\n",
    "\n",
    "# Write the processed HTML to a new file\n",
    "with open('processed_www.selenium.dev_full.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(str(soup))\n",
    "\n",
    "# Combine the processed chunks\n",
    "processed_html_body = ''.join(processed_chunks)\n",
    "\n",
    "# Reconstruct the HTML with the original head and new body\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "soup.body.clear()\n",
    "soup.body.append(BeautifulSoup(processed_html_body, 'html.parser'))\n",
    "\n",
    "# Write the processed HTML to a new file\n",
    "with open('processed_www.selenium.dev_full_concurrent.html', 'w', encoding='utf-8') as file:\n",
    "    file.write(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "webbrowser.open(url = \"processed_www.selenium.dev.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI \n",
    "from langchain_core.prompts import ChatPromptTemplate \n",
    "from Web_Page_Class_and_Tests_2.Web_Page_Prompt_Templates.Chunks import template_chunks\n",
    "import asyncio\n",
    "\n",
    "llm = ChatOpenAI(model = \"gpt-4o-mini\", temperature = 0) \n",
    "\n",
    "template = template_chunks \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template = template) \n",
    "\n",
    "chain = prompt | llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_chain(original_chunk): \n",
    "    return await chain.ainvoke({\"original_html_code_chunks\": original_chunk}) \n",
    "\n",
    "async def run_multiple_chains(original_chunks): \n",
    "    tasks = [run_chain(chunk) for chunk in original_chunks] \n",
    "    outputs = await asyncio.gather(*tasks) \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_output_async = asyncio.run(run_multiple_chains(chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(example_output_async)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_output = chain.batch(inputs = [chunks])\n",
    "\n",
    "batch_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[1;32m     42\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m process_html_async(html_content)\n\u001b[0;32m---> 44\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/Web_Page_Transformer/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "\n",
    "# Create prompt template for HTML processing\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"html_chunk\"],\n",
    "    template=\"Summarize this HTML content: {html_chunk}\"\n",
    ")\n",
    "\n",
    "# Initialize the chain\n",
    "llm = ChatOpenAI()\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Synchronous batch processing\n",
    "def process_html_sync(html_content):\n",
    "    chunks = split_html(html_content)\n",
    "    # Process all chunks in parallel\n",
    "    results = chain.batch(\n",
    "        [{\"html_chunk\": chunk} for chunk in chunks]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Asynchronous batch processing\n",
    "async def process_html_async(html_content):\n",
    "    chunks = split_html(html_content)\n",
    "    # Process all chunks in parallel asynchronously\n",
    "    results = await chain.abatch(\n",
    "        [{\"html_chunk\": chunk} for chunk in chunks]\n",
    "    )\n",
    "    return results\n",
    "\n",
    "# Example usage\n",
    "html_content = \"<html><body><p>Some content</p></body></html>\"\n",
    "# Sync\n",
    "results = process_html_sync(html_content)\n",
    "\n",
    "# Async\n",
    "async def main():\n",
    "    results = await process_html_async(html_content)\n",
    "\n",
    "asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Web_Page_Transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
